# -*- coding: utf-8 -*-
"""submission_ml_dadandw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jkdRM_z6lanFyRWH4lTexpIKwkAePrmM

**Nama : Dadan Dahman Wahidi**

**Proyek Pertama : Membuat Model NLP dengan TensorFlow**

Keterangan Proyek Akhir :

    Dataset yang dipakai adalah bersumber dari : https://www.kaggle.com/atulanandjha/imdb-50k-movie-reviews-test-your-bert
    Menggunakan LSTM dalam arsitektur model.
    Menggunakan model sequential.
    Validation set sebesar 20% dari total dataset.
    Menggunakan Embedding.
    Menggunakan model sequential.
    Menggunakan fungsi tokenizer.
    Mengimplementasikan Callback
    Plot loss dan akurasi
    Program dikerjakan pada Google Colaboratory.
    Menggunakan bahasa pemrograman Python.

# Multiclass Text Classification
"""

from google.colab import drive
drive.mount('/content/drive/')

"""Kita akan melakukan klasifikasi teks multikelas menggunakan lstm.

Pada latihan ini kita akan menggunakan dataset yang berisi review beberapa film. Dataset dapat Anda unduh pada [tautan](https://www.kaggle.com/atulanandjha/imdb-50k-movie-reviews-test-your-bert) berikut.

### Load Dataset
Pada cell pertama impor library pandas dan ubah dataset menjadi dataframe.
"""

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dicoding/dataset/review_film.csv')

df

"""### Callback
Kemudian kita buat function callback, fungsinya untuk mencegah adanya overfitting dan menghentikan training setelah selesai mengakurasi.
"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.95):
      print("\nAkurasi di atas 95%, Training Berhenti!")
      self.model.stop_training = True

callbacks = myCallback()

"""### Encoding

Ubah bentuk data pada kolom sentiment menjadi bentuk angka untuk labeling setiap data.
"""

cat = pd.get_dummies(df.sentiment)
df = pd.concat([df, cat], axis=1)
df = df.drop(columns='sentiment')

df

"""### Split Dataframe

Agar dapat diproses oleh model, kita perlu mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values.
"""

review = df['text'].values
label = df[['neg', 'pos']].values

review

label

from sklearn.model_selection import train_test_split

text = df['text'].values
y = df[['pos','neg']].values
text_train , text_test, y_train, y_test = train_test_split(text, y, test_size=0.2)

"""### Tokenizer
Kemudian kita ubah setiap kata pada dataset kita ke dalam bilangan numerik dengan fungsi Tokenizer. Setelah tokenisasi selesai, kita perlu membuat mengonversi setiap sampel menjadi sequence.
"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

#tokenizer
tokenizer = Tokenizer(num_words=280617, oov_token='-')
tokenizer.fit_on_texts(text_train)
tokenizer.fit_on_texts(text_test)

#sequences
seq_train = tokenizer.texts_to_sequences(text_train)
seq_test = tokenizer.texts_to_sequences(text_test)

#padding
pad_train = pad_sequences(seq_train,
                          maxlen=300,
                          padding='post',
                          truncating='post')

pad_test = pad_sequences(seq_test,
                         maxlen=300,
                         padding='post',
                         truncating='post')

"""### Embedding

Untuk arsitektur model kita menggunakan layer Embedding dengan dimensi embedding sebesar 16, serta dimensi dari input sebesar nilai num_words pada objek tokenizer. Jangan lupa panggil fungsi compile dan tentukan optimizer serta loss function yang akan dipakai oleh model.
"""

from tensorflow.keras import layers
from tensorflow.keras import Sequential

model = Sequential([layers.Embedding(280617, 64, input_length=300),
                    layers.LSTM(64, dropout=0.1),
                    layers.Dense(128, activation='relu'),
                    layers.Dense(64, activation='relu'),
                    layers.Dense(2, activation='sigmoid')])
model.summary()

"""# Training Model
Terakhir kita dapat mulai melatih model kita dengan memanggil fungsi fit().
"""

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

history = model.fit(pad_train, y_train,
                    batch_size=128,
                    epochs=30,
                    validation_data=(pad_test, y_test),
                    verbose=2,
                    callbacks=[callbacks])

"""### Evaluation Model
Gunakan library matplotlib untuk membuat plot model
"""

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

plt.legend(['Train', 'Test'], loc='lower right')
plt.show()

